# Define a base configuration to avoid repetition
x-airflow-base: &airflow-base
  build:
    context: .
    dockerfile: Dockerfile
    args:
      # Since we've sent the user ID to 1000 (which is the same as username in Linux) in credentials.env, that will flow into docker-compose.yaml as AIRFLOW_UID as 1000 as well
      - AIRFLOW_UID=${AIRFLOW_UID}
  user: "${AIRFLOW_UID:-1000}:0"   # run as your host UID, group root
  # Use the .env with RDS credentials in base folder: financial-etl-poc/.env
  env_file:
    - ../credentials.env
  environment:
    # Construct the database connection string from your .env variables
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${rds_username}:${rds_password}@${rds_host}:${rds_port}/${rds_dbname}
    # Set other core Airflow configurations
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__LOAD_EXAMPLES=false
    - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
    - AIRFLOW__WEBSERVER__SECRET_KEY=${WEBSERVER_SECRET_KEY:-your-super-secret-key-change-me} # Add a default secret key
  volumes:
    - ./config:/opt/airflow/config
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins

services:

  # The service that initializes the Airflow database and creates the first user
  airflow-init:
    <<: *airflow-base
    container_name: airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        # Initialize the database
        airflow db init
        # Create the admin user if they don't exist
        airflow users create \
          --username ${AIRFLOW_USERNAME} \
          --password ${AIRFLOW_PASSWORD} \
          --firstname Joe \
          --lastname Lu \
          --role Admin \
          --email Joe.Zhou.Lu@gmail.com || true

  # The Airflow webserver service
  airflow-webserver:
    <<: *airflow-base
    container_name: airflow_webserver
    restart: always
    command: airflow webserver
    ports:
      - "8080:8080"
    depends_on:
      # This ensures the webserver only starts after the database is initialized
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # The Airflow scheduler service
  airflow-scheduler:
    <<: *airflow-base
    container_name: airflow_scheduler
    restart: always
    command: airflow scheduler
    depends_on:
      # This ensures the scheduler only starts after the database is initialized
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\""]
      interval: 30s
      timeout: 10s
      retries: 3